> * åŸæ–‡åœ°å€ï¼š[Linear Algebra for Deep Learning](https://towardsdatascience.com/linear-algebra-for-deep-learning-506c19c0d6fa)
> * åŸæ–‡ä½œè€…ï¼š[Vihar Kurama](https://towardsdatascience.com/@vihar.kurama?source=post_header_lockup)
> * è¯‘æ–‡å‡ºè‡ªï¼š[æ˜é‡‘ç¿»è¯‘è®¡åˆ’](https://github.com/xitu/gold-miner)
> * æœ¬æ–‡æ°¸ä¹…é“¾æ¥ï¼š[https://github.com/xitu/gold-miner/blob/master/TODO1/linear-algebra-for-deep-learning.md](https://github.com/xitu/gold-miner/blob/master/TODO1/linear-algebra-for-deep-learning.md)
> * è¯‘è€…ï¼š
> * æ ¡å¯¹è€…ï¼š

# æ·±åº¦å­¦ä¹ ä¸­æ‰€éœ€çš„çº¿æ€§ä»£æ•°çŸ¥è¯†

æ¯ä¸ªæ·±åº¦å­¦ä¹ é¡¹ç›®èƒŒåçš„æ•°å­¦çŸ¥è¯†ã€‚

**æ·±åº¦å­¦ä¹ **æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ,æ¶‰åŠä¸€äº›æ¨¡ä»¿äººè„‘ç»“æ„å’ŒåŠŸèƒ½çš„äººå·¥ç¥ç»ç½‘ç»œç®—æ³•ã€‚

**çº¿æ€§ä»£æ•°**æ˜¯ä¸€ç§è¿ç»­çš„è€Œéç¦»æ•£çš„æ•°å­¦å½¢å¼,è®¸å¤šè®¡ç®—æœºç§‘å­¦å®¶å¯¹å®ƒå‡ ä¹æ²¡æœ‰ç»éªŒã€‚å¯¹äºç†è§£å’Œä½¿ç”¨è®¸å¤šæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦å­¦ä¹ ç®—æ³•ï¼Œç†è§£çº¿æ€§ä»£æ•°æ˜¯éå¸¸é‡è¦çš„ã€‚

![](https://cdn-images-1.medium.com/max/1000/1*oOS8U37MHmJ7Vl8nqnepiA.jpeg)

### ä¸ºä»€ä¹ˆæ˜¯æ•°å­¦?

çº¿æ€§ä»£æ•°ï¼Œæ¦‚ç‡ç‡å’Œå¾®ç§¯åˆ†æ˜¯ç»„æˆæœºå™¨å­¦ä¹ çš„ä¸‰ç§â€œè¯­è¨€â€ã€‚å­¦ä¹ è¿™äº›æ•°å­¦çŸ¥è¯†å°†æœ‰åŠ©äºæ·±å…¥ç†è§£åº•å±‚ç®—æ³•æœºåˆ¶ï¼Œå¹¶ä¸”å¼€å‘æ–°çš„ç®—æ³•ã€‚

å½“æˆ‘ä»¬æ·±å…¥åˆ°åº•å±‚æ—¶ï¼Œæ·±åº¦å­¦ä¹ èƒŒåçš„ä¸€åˆ‡éƒ½æ˜¯æ•°å­¦ã€‚å› æ­¤åœ¨å­¦ä¹ æ·±åº¦å­¦ä¹ å’Œç¼–ç¨‹ä¹‹å‰ï¼Œç†è§£åŸºæœ¬çš„çº¿æ€§ä»£æ•°çŸ¥è¯†æ˜¯è‡³å…³é‡è¦çš„ã€‚

![](https://cdn-images-1.medium.com/max/800/1*pUr-9ctuGamgjSwoW_KU-A.png)

[æºç ](https://hadrienj.github.io/posts/Deep-Learning-Book-Series-2.1-Scalars-Vectors-Matrices-and-Tensors/)

æ·±åº¦å­¦ä¹ èƒŒåçš„æ ¸å¿ƒæ•°æ®ç»“æ„æ˜¯æ ‡é‡ï¼ŒçŸ¢é‡ï¼ŒçŸ©é˜µå’Œå¼ é‡ã€‚è®©æˆ‘ä»¬ä½¿ç”¨è¿™äº›ï¼Œé€šè¿‡ç¼–ç¨‹çš„æ–¹å¼æ¥è§£å†³æ‰€æœ‰åŸºæœ¬çš„ çº¿æ€§ä»£æ•°é—®é¢˜ã€‚

### æ ‡é‡

æ ‡é‡æ˜¯**å•ä¸ªæ•°å­—**ï¼Œæ˜¯ 0 é˜¶å¼ é‡çš„ä¾‹å­ã€‚ ç¬¦å· x âˆˆ â„ è¡¨ç¤º x æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå±äºä¸€ç»„å®æ•°å€¼ â„ ã€‚

ä»¥ä¸‹æ˜¯æ·±åº¦å­¦ä¹ ä¸­ä¸åŒæ•°é›†çš„è¡¨ç¤ºã€‚ â„• è¡¨ç¤ºæ­£æ•´æ•°é›†åˆ (1,2,3,â€¦)ã€‚ â„¤ è¡¨ç¤ºç»“åˆäº†æ­£å€¼ï¼Œè´Ÿå€¼å’Œé›¶å€¼çš„æ•´æ•°é›†åˆã€‚ â„š è¡¨ç¤ºæœ‰ç†æ•°é›†åˆã€‚

åœ¨ Python ä¸­æœ‰ä¸€äº›å†…ç½®çš„æ ‡é‡ç±»å‹ï¼Œ**int**, **float**, **complex**, **bytes**, **Unicode** ã€‚åœ¨ Numpy ï¼ˆä¸€ä¸ª Python åº“ï¼‰ä¸­ï¼Œæœ‰24ç§æ–°çš„åŸºæœ¬æ•°æ®ç±»å‹æ¥æè¿°ä¸åŒç±»å‹çš„æ ‡é‡ã€‚æœ‰å…³æ•°æ®ç±»å‹çš„ä¿¡æ¯ï¼Œè¯·å‚é˜…æ–‡æ¡£ [è¿™é‡Œ](https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.scalars.html).

**åœ¨ Python ä¸­å®šä¹‰æ ‡é‡å’Œç›¸å…³æ“ä½œ:**

ä¸‹é¢çš„ä»£ç æ®µè§£é‡Šäº†ä¸€äº›è¿ç®—è¿ç®—ç¬¦åœ¨æ ‡é‡ä¸­çš„åº”ç”¨ã€‚

```
# å†…ç½®æ ‡é‡
a = 5
b = 7.5
print(type(a))
print(type(b))
print(a + b)
print(a - b)
print(a * b)
print(a / b)
```

```
<class 'int'>  
<class 'float'>  
12.5  
-2.5  
37.5  
0.6666666666666666
```

ä¸‹é¢çš„ä»£ç æ®µå¯ä»¥æ£€æŸ¥ç»™å‡ºçš„å˜é‡æ˜¯å¦ä¸ºæ ‡é‡ã€‚

```
import numpy as np

# åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é‡çš„å‡½æ•°
def isscalar(num):
    if isinstance(num, generic):
        return True
    else:
        return False

print(np.isscalar(3.1))
print(np.isscalar([3.1]))
print(np.isscalar(False))
```

```
True  
False  
True
```

### å‘é‡

å‘é‡æ˜¯å•æ•°çš„æœ‰åºæ•°ç»„ï¼Œæ˜¯ä¸€é˜¶å¼ é‡çš„ä¾‹å­ã€‚é‡æ˜¯è¢«ç§°ä¸ºçŸ¢é‡ç©ºé—´çš„å¯¹è±¡çš„ç‰‡æ®µã€‚å‘é‡ç©ºé—´å¯ä»¥è¢«è®¤ä¸ºæ˜¯ç‰¹å®šé•¿åº¦ï¼ˆæˆ–ç»´åº¦ï¼‰çš„æ‰€æœ‰å¯èƒ½å‘é‡çš„æ•´ä¸ªé›†åˆã€‚ç”¨ â„^3 è¡¨ç¤ºçš„ä¸‰ç»´å®å€¼å‘é‡ç©ºé—´ï¼Œé€šå¸¸ç”¨äºä»æ•°å­¦è§’åº¦è¡¨ç¤ºæˆ‘ä»¬å¯¹ä¸‰ç»´ç©ºé—´çš„ç°å®ä¸–ç•Œæ¦‚å¿µã€‚

![](https://cdn-images-1.medium.com/max/800/1*fHS5crNOYBxDGASNPSp5lw.png)

ä¸ºäº†æ˜ç¡®åœ°è¯†åˆ«çŸ¢é‡çš„å¿…è¦åˆ†é‡ï¼ŒçŸ¢é‡çš„ç¬¬ i ä¸ªæ ‡é‡å…ƒç´ è¢«å†™ä¸º x[i] ã€‚

åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå‘é‡é€šå¸¸ä»£è¡¨ç‰¹å¾å‘é‡ï¼Œå…¶åŸå§‹ç»„æˆéƒ¨åˆ†å®šä¹‰äº†å…·ä½“ç‰¹å¾çš„ç›¸å…³æ€§ã€‚

**åœ¨ Python ä¸­å®šä¹‰å‘é‡å’Œç›¸å…³æ“ä½œ:**

```
import numpy as np

# å®šä¹‰å‘é‡

x = [1, 2, 3]
y = [4, 5, 6]

print(type(x))

# å‘é‡ä¸ä¼šç›¸åŠ 
print(x + y)

# ä½¿ç”¨ Numpy è¿›è¡Œå‘é‡ç›¸åŠ 

z = np.add(x, y)
print(z)
print(type(z))

# å‘é‡äº¤å‰
mul = np.cross(x, y)
print(mul)
```

```
<class 'list'>
[1, 2, 3, 4, 5, 6]
[5 7 9]
<class 'numpy.ndarray'>
[-3  6 -3]
```

### çŸ©é˜µ

çŸ©é˜µæ˜¯ç”±æ•°å­—ç»„æˆçš„çŸ©å½¢é˜µåˆ—ï¼Œæ˜¯ 2 é˜¶å¼ é‡çš„ä¸€ä¸ªä¾‹å­ã€‚å¦‚æœ m å’Œ n æ˜¯æ­£æ•´æ•°ï¼Œå³ mï¼Œnâˆˆâ„•ï¼Œåˆ™ mÃ—n çŸ©é˜µåŒ…å« m * n ä¸ªæ•°å­—ï¼Œm è¡Œ n åˆ—ã€‚

å®Œæ•´çš„mÃ—nçŸ©é˜µå¯å†™ä¸ºï¼š

![](https://cdn-images-1.medium.com/max/800/1*x0q53AIuUG4i6U7BMjjUzg.png)

å°†å…¨çŸ©é˜µæ˜¾ç¤ºç®€å†™ä¸ºä»¥ä¸‹è¡¨è¾¾å¼é€šå¸¸å¾ˆæœ‰ç”¨ï¼š

![](https://cdn-images-1.medium.com/max/800/1*RGmyzL1tmF4so67kxYUF1g.png)

åœ¨Pythonä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ Numpy åº“æ¥å¸®åŠ©æˆ‘ä»¬åˆ›å»º N ç»´æ•°ç»„ã€‚æ•°ç»„åŸºæœ¬ä¸Šå¯çœ‹åšçŸ©é˜µï¼Œæˆ‘ä»¬ä½¿ç”¨çŸ©é˜µæ–¹æ³•ï¼Œå¹¶é€šè¿‡åˆ—è¡¨æ¥æ„é€ ä¸€ä¸ªçŸ©é˜µã€‚

$python

```
>>> import numpy as np
>>> x = np.matrix([[1,2],[2,3]])
>>> x
matrix([[1, 2],
        [2, 3]])

>>> a = x.mean(0)
>>> a
matrix([[1.5, 2.5]])
>>> # Finding the mean with 1 with the matrix x.
>>> z = x.mean(1)
>>> z
matrix([[ 1.5],
        [ 2.5]])
>>> z.shape
(2, 1)
>>> y = x - z
matrix([[-0.5,  0.5],
        [-0.5,  0.5]])
>>> print(type(z))
<class 'numpy.matrixlib.defmatrix.matrix'>
```

**åœ¨ Python ä¸­å®šä¹‰çŸ©é˜µå’Œç›¸å…³æ“ä½œï¼š**

#### çŸ©é˜µåŠ æ³•

çŸ©é˜µå¯ä»¥ä¸æ ‡é‡ã€å‘é‡å’Œå…¶ä»–çŸ©é˜µè¿›è¡ŒåŠ æ³•è¿ç®—ã€‚æ¯ä¸ªæ“ä½œéƒ½æœ‰ç²¾ç¡®çš„å®šä¹‰ã€‚è¿™äº›æŠ€æœ¯ç»å¸¸ç”¨äºæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ï¼Œæ‰€ä»¥å€¼å¾—ç†Ÿæ‚‰å®ƒä»¬ã€‚

```
# çŸ©é˜µåŠ æ³•

import numpy as np

x = np.matrix([[1, 2], [4, 3]])

sum = x.sum()
print(sum)
# Output: 10
```

#### çŸ©é˜µä¸çŸ©é˜µç›¸åŠ 

C = A + B (*A ä¸ B çš„ç»´åº¦éœ€è¦ç›¸åŒ*)

æ–¹æ³•çš„`shape`å‚æ•°è¿”å›çŸ©é˜µçš„ç»´åº¦ï¼Œç„¶åå°†ä¸¤ä¸ªå‚æ•°ç›¸åŠ å¹¶è¿”å›çŸ©é˜µçš„å’Œã€‚å¦‚æœçŸ©é˜µçš„ç»´åº¦ä¸åŒï¼Œè¯¥æ–¹æ³•åˆ™ä¼šæŠ›å‡ºä¸€ä¸ªå¼‚å¸¸ï¼Œæ— æ³•è¿›è¡ŒçŸ©é˜µç›¸åŠ æ“ä½œã€‚

```
# çŸ©é˜µä¸çŸ©é˜µç›¸åŠ 

import numpy as np

x = np.matrix([[1, 2], [4, 3]])
y = np.matrix([[3, 4], [3, 10]])

print(x.shape)
# (2, 2)
print(y.shape)
# (2, 2)

m_sum = np.add(x, y)
print(m_sum)
print(m_sum.shape)
"""
Output : 
[[ 4  6]
 [ 7 13]]
(2, 2)
"""
```

#### çŸ©é˜µä¸æ ‡é‡ç›¸åŠ 

å°†ç»™å®šçš„æ ‡é‡æ·»åŠ åˆ°ç»™å®šçŸ©é˜µä¸­çš„æ‰€æœ‰å…ƒç´ ã€‚

```
# çŸ©é˜µä¸æ ‡é‡ç›¸åŠ 

import numpy as np

x = np.matrix([[1, 2], [4, 3]])
s_sum = x + 1
print(s_sum)
"""
Output:
[[2 3]
 [5 4]]
"""
```

#### çŸ©é˜µä¸æ ‡é‡çš„ä¹˜æ³•

å°†ç»™å®šçš„æ ‡é‡ä¹˜ä»¥ç»™å®šçŸ©é˜µä¸­çš„æ‰€æœ‰å…ƒç´ ã€‚

```
# çŸ©é˜µä¸æ ‡é‡çš„ä¹˜æ³•

import numpy as np

x = np.matrix([[1, 2], [4, 3]])
s_mul = x * 3
print(s_mul)
"""
[[ 3  6]
 [12  9]]
"""
```

#### çŸ©é˜µä¹˜æ³•

ç»´åº¦ä¸º(m x n)çš„çŸ©é˜µ A å’Œç»´åº¦ä¸º(n x p)çš„çŸ©é˜µ B ç›¸ä¹˜ï¼Œæœ€ç»ˆå¾—åˆ°ç»´åº¦ä¸º(m x p)çš„çŸ©é˜µ Cã€‚

![](https://cdn-images-1.medium.com/max/800/1*96qrPHcvXBVM01I1lUKS8g.png)

[æºç ](https://hadrienj.github.io/posts/Deep-Learning-Book-Series-2.2-Multiplying-Matrices-and-Vectors/)

```
# çŸ©é˜µä¹˜æ³•

import numpy as np

a = [[1, 0], [0, 1]]
b = [1, 2]
np.matmul(a, b)
# Output: array([1, 2])

complex_mul = np.matmul([2j, 3j], [2j, 3j])
print(complex_mul)
# Output: (-13+0j)
```

#### çŸ©é˜µè½¬ç½®

é€šè¿‡è½¬ç½®ï¼Œæ‚¨å¯ä»¥å°†è¡Œå‘é‡è½¬æ¢ä¸ºåˆ—å‘é‡ï¼Œåä¹‹äº¦ç„¶ï¼š

A=[a_ij_]mxn

AT=[a_ji_]nÃ—m

![](https://cdn-images-1.medium.com/max/800/1*VUByXk3gxhNuQVSTmcS2Gg.png)

```

# çŸ©é˜µè½¬ç½®

import numpy as np

a = np.array([[1, 2], [3, 4]])
print(a)
"""
[[1 2]
 [3 4]]
"""
a.transpose()
print(a)
"""
array([[1, 3],
       [2, 4]])
"""
```

### å¼ é‡

æ›´å…·ä¸€èˆ¬æ€§çš„å®ä½“â€”â€”å¼ é‡ï¼Œå°è£…äº†æ ‡é‡ã€çŸ¢é‡å’ŒçŸ©é˜µã€‚åœ¨ç‰©ç†ç§‘å­¦å’Œæœºå™¨å­¦ä¹ ä¸­,æœ‰æ—¶éœ€è¦ä½¿ç”¨è¶…è¿‡ä¸¤ä¸ªé¡ºåºçš„å¼ é‡ã€‚

![](https://cdn-images-1.medium.com/max/800/1*gyd_WcgWOPYncAsR6Z0IKQ.png)

[æºç ](https://refactored.ai/track/python-for-machine-learning/courses/linear-algebra.ipynb)

æˆ‘ä»¬ä½¿ç”¨åƒ Tensorflow æˆ– PyTorch è¿™æ ·çš„Pythonåº“æ¥å£°æ˜å¼ é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨åµŒå¥—çŸ©é˜µæ¥è¡¨ç¤ºã€‚

**åœ¨ PyTorch ä¸­å®šä¹‰ä¸€ä¸ªç®€å•çš„å¼ é‡ï¼š**

```

import torch

a = torch.Tensor([26])

print(type(a))
# <class 'torch.FloatTensor'>

print(a.shape)
# torch.Size([1])

# åˆ›å»ºä¸€ä¸ª5*3çš„éšæœºtorchå˜é‡ã€‚
t = torch.Tensor(5, 3)
print(t)
"""
 0.0000e+00  0.0000e+00  0.0000e+00
 0.0000e+00  7.0065e-45  1.1614e-41
 0.0000e+00  2.2369e+08  0.0000e+00
 0.0000e+00  0.0000e+00  0.0000e+00
        nan         nan -1.4469e+35
[torch.FloatTensor of size 5x3]
"""
print(t.shape)
# torch.Size([5, 3])
```

**Python ä¸­ä¸€äº›ä½œç”¨åœ¨å¼ é‡ä¸­çš„è¿ç®—ç¬¦ï¼š**

```
import torch

# åˆ›å»ºå¼ é‡

p = torch.Tensor(4,4)
q = torch.Tensor(4,4)
ones = torch.ones(4,4)

print(p, q, ones)
"""
Output:
 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00
 1.6009e-19  4.4721e+21  6.2625e+22  4.7428e+30
 3.1921e-09  8.0221e+17  5.1019e-08  8.1121e+17
 8.1631e-07  8.2022e+17  1.1703e-19  1.5637e-01
[torch.FloatTensor of size 4x4]
 
 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00
 1.8217e-44  1.1614e-41  0.0000e+00  2.2369e+08
 0.0000e+00  0.0000e+00  2.0376e-40  2.0376e-40
        nan         nan -5.3105e+37         nan
[torch.FloatTensor of size 4x4]
 
 1  1  1  1
 1  1  1  1
 1  1  1  1
 1  1  1  1
[torch.FloatTensor of size 4x4]
"""

print("Addition:{}".format(p + q))
print("Subtraction:{}".format(p - ones))
print("Multiplication:{}".format(p * ones))
print("Division:{}".format(q / ones))

"""
Addition:
 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00
 1.6009e-19  4.4721e+21  6.2625e+22  4.7428e+30
 3.1921e-09  8.0221e+17  5.1019e-08  8.1121e+17
        nan         nan -5.3105e+37         nan
[torch.FloatTensor of size 4x4]
Subtraction:
-1.0000e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00
-1.0000e+00  4.4721e+21  6.2625e+22  4.7428e+30
-1.0000e+00  8.0221e+17 -1.0000e+00  8.1121e+17
-1.0000e+00  8.2022e+17 -1.0000e+00 -8.4363e-01
[torch.FloatTensor of size 4x4]
Multiplication:
 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00
 1.6009e-19  4.4721e+21  6.2625e+22  4.7428e+30
 3.1921e-09  8.0221e+17  5.1019e-08  8.1121e+17
 8.1631e-07  8.2022e+17  1.1703e-19  1.5637e-01
[torch.FloatTensor of size 4x4]
Division:
 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00
 1.8217e-44  1.1614e-41  0.0000e+00  2.2369e+08
 0.0000e+00  0.0000e+00  2.0376e-40  2.0376e-40
        nan         nan -5.3105e+37         nan
[torch.FloatTensor of size 4x4]
"""
```

æœ‰å…³å¼ é‡å’ŒPyTorchçš„æ›´å¤šæ–‡æ¡£ [ç‚¹å‡»è¿™é‡Œ](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).

* * *

**é‡è¦çš„é“¾æ¥**

åœ¨Pythonä¸­å…¥é—¨æ·±åº¦å­¦ä¹ :

* [**Deep Learning with Python**: The human brain imitation.](https://towardsdatascience.com/deep-learning-with-python-703e26853820)
* [**Introduction To Machine Learning**: Machine Learning is an idea to learn from examples and experience, without being explicitly programmed. Instead ofâ€¦](https://towardsdatascience.com/introduction-to-machine-learning-db7c668822c4)

### ç»“æŸè¯­

æ„Ÿè°¢é˜…è¯»ã€‚ å¦‚æœä½ å‘ç°è¿™ä¸ªæ•…äº‹å¾ˆæœ‰ç”¨, è¯·ç‚¹å‡»ä¸‹é¢çš„ ğŸ‘ æ¥ä¼ æ’­çˆ±å¿ƒ.

ç‰¹åˆ«é¸£è°¢ [Samhita Alla](https://medium.com/@allasamhita) å¯¹æœ¬æ–‡çš„è´¡çŒ®.

> å¦‚æœå‘ç°è¯‘æ–‡å­˜åœ¨é”™è¯¯æˆ–å…¶ä»–éœ€è¦æ”¹è¿›çš„åœ°æ–¹ï¼Œæ¬¢è¿åˆ° [æ˜é‡‘ç¿»è¯‘è®¡åˆ’](https://github.com/xitu/gold-miner) å¯¹è¯‘æ–‡è¿›è¡Œä¿®æ”¹å¹¶ PRï¼Œä¹Ÿå¯è·å¾—ç›¸åº”å¥–åŠ±ç§¯åˆ†ã€‚æ–‡ç« å¼€å¤´çš„ **æœ¬æ–‡æ°¸ä¹…é“¾æ¥** å³ä¸ºæœ¬æ–‡åœ¨ GitHub ä¸Šçš„ MarkDown é“¾æ¥ã€‚


---

> [æ˜é‡‘ç¿»è¯‘è®¡åˆ’](https://github.com/xitu/gold-miner) æ˜¯ä¸€ä¸ªç¿»è¯‘ä¼˜è´¨äº’è”ç½‘æŠ€æœ¯æ–‡ç« çš„ç¤¾åŒºï¼Œæ–‡ç« æ¥æºä¸º [æ˜é‡‘](https://juejin.im) ä¸Šçš„è‹±æ–‡åˆ†äº«æ–‡ç« ã€‚å†…å®¹è¦†ç›– [Android](https://github.com/xitu/gold-miner#android)ã€[iOS](https://github.com/xitu/gold-miner#ios)ã€[å‰ç«¯](https://github.com/xitu/gold-miner#å‰ç«¯)ã€[åç«¯](https://github.com/xitu/gold-miner#åç«¯)ã€[åŒºå—é“¾](https://github.com/xitu/gold-miner#åŒºå—é“¾)ã€[äº§å“](https://github.com/xitu/gold-miner#äº§å“)ã€[è®¾è®¡](https://github.com/xitu/gold-miner#è®¾è®¡)ã€[äººå·¥æ™ºèƒ½](https://github.com/xitu/gold-miner#äººå·¥æ™ºèƒ½)ç­‰é¢†åŸŸï¼Œæƒ³è¦æŸ¥çœ‹æ›´å¤šä¼˜è´¨è¯‘æ–‡è¯·æŒç»­å…³æ³¨ [æ˜é‡‘ç¿»è¯‘è®¡åˆ’](https://github.com/xitu/gold-miner)ã€[å®˜æ–¹å¾®åš](http://weibo.com/juejinfanyi)ã€[çŸ¥ä¹ä¸“æ ](https://zhuanlan.zhihu.com/juejinfanyi)ã€‚
