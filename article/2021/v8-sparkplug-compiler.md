> * 原文地址：[V8 Gets a Non-Optimizing Compiler Stage to Improve Performance](https://www.infoq.com/news/2021/06/v8-sparkplug-compiler/)
> * 原文作者：[Sergio De Simone](https://www.infoq.com/profile/Sergio-De-Simone/)
> * 译文出自：[掘金翻译计划](https://github.com/xitu/gold-miner)
> * 本文永久链接：[https://github.com/xitu/gold-miner/blob/master/article/2021/v8-sparkplug-compiler.md](https://github.com/xitu/gold-miner/blob/master/article/2021/v8-sparkplug-compiler.md)
> * 译者：
> * 校对者：

# V8 Gets a Non-Optimizing Compiler Stage to Improve Performance

The latest version of the JavaScript V8 engine, V8 9.1, introduces a new intermediate compiler stage, called [Sparkplug](https://v8.dev/blog/sparkplug), that improves performance on real-world benchmarks by 5-15%, says V8 engineer [Leszek Swirski](https://twitter.com/leszekswirski). It will be available in the upcoming Chrome 91.

The old V8 architecture included just two stages: Ignition, a JavaScript interpreter, and TurboFan, a highly optimising compiler. Ignition takes a JavaScript AST and generates V8 bytecode, while TurboFan is able to generate machine code from that. The reason for the introduction of Sparkplug is clearly explained in the [Sparkplug design](https://docs.google.com/document/d/1NeOsqjPPAcDWbuHxW5MobzVQgj9qZd6NqKUnz0h-fOw/edit) overview:

> There is a big performance cliff between \[Ignition and TurboFan\]; staying too long in the interpreter means we don’t take advantage of optimisation, but calling TurboFan too early might mean we “waste” time optimising functions that aren’t actually hot — or worse, it means we deopt. We can reduce this gap with a simple, fast, non-optimising compiler, that can quickly and cheaply tier-up from the interpreter by linearly walking the bytecode and spitting out machine code. We call this compiler Sparkplug.

Before the introduction of Ignition and TurboFan, V8 used to have a fast JIT compiler called Full-CodeGen (FCG). As Leszek [explains in a Hacker News thread](https://news.ycombinator.com/item?id=27307862), this was ditched in favour of a new interpreter architecture, called Ignition, which did not include FCG.

> The big difference is that Sparkplug compiles from bytecode, not from source, and thus the bytecode stays the source of truth for the program. Back in the FCG days, the optimising compiler had to re-parse the source code to AST, and compile from there - even worse, to be able to deoptimise back to FCG, it had to kind of "replay" FCG compilation to get the deopted stack frame right.

Leszek [mentions](https://news.ycombinator.com/item?id=27312037) that FCG was ditched instead of evolved because of its massive technical debt, specifically related to the fact that both the Ignition compiler and FCG had to compile from source and provide their output to TurboFan, which led to all kind of complexities. This also [made it harder to keep up with JavaScript new features](https://v8project.blogspot.com/2017/05/launching-ignition-and-turbofan.html).

Sparkplug speed comes from two factors, says Swirski. First, it relies on bytecode generated by Ignition, which means a bunch of work has already been done, including variable resolution, figuring out if parentheses are actually arrow functions, desugaring destructuring statements, and so on. Additionally, Sparkplug does not generate any intermediate representation (IR), rather it outputs machine code in a single linear pass. This approach means Sparkplug cannot do any advanced optimizations based on IR and it must be entirely ported to each new platform.

When it comes to performance, Sparkplug improves both the [Speedometer](https://browserbench.org/Speedometer2.0/) as well as a set of real-world benchmarks used by the V8 team. The improvement is in the range of 5-15% depending of test machine and website. Google has not released official low-level benchmarks comparing the various pipeline components' performance. Leszek, though, [explains](https://news.ycombinator.com/item?id=27308038) that:

> Compile time is on roughly the same order of magnitude as Ignition compilation (just AST to bytecode, so excluding parsing), and roughly two to three orders of magnitude faster that TurboFan. The relative performance to the interpreter, as the sibling comments point out, varies **wildly** by workload, but around 4x is probably a decent approximation for something not entirely dominated by property loads.

Besides performance, another key benefit of Sparkplug is reduced CPU usage, which can improve battery usage on mobile devices as well as reduce the bill on pay-per-cycle servers, according to V8 designers.

As mentioned, Sparkplug is being [currently rolled out in Chrome 91](https://developer.chrome.com/blog/new-in-chrome-91/) so you will soon be able to try it out.  If you are interested in the nitty-gritty details of Sparkplug internals and the way it interfaces with Ignition and TurboFan, do not miss Swirski's writeup.

> 如果发现译文存在错误或其他需要改进的地方，欢迎到 [掘金翻译计划](https://github.com/xitu/gold-miner) 对译文进行修改并 PR，也可获得相应奖励积分。文章开头的 **本文永久链接** 即为本文在 GitHub 上的 MarkDown 链接。

---

> [掘金翻译计划](https://github.com/xitu/gold-miner) 是一个翻译优质互联网技术文章的社区，文章来源为 [掘金](https://juejin.im) 上的英文分享文章。内容覆盖 [Android](https://github.com/xitu/gold-miner#android)、[iOS](https://github.com/xitu/gold-miner#ios)、[前端](https://github.com/xitu/gold-miner#前端)、[后端](https://github.com/xitu/gold-miner#后端)、[区块链](https://github.com/xitu/gold-miner#区块链)、[产品](https://github.com/xitu/gold-miner#产品)、[设计](https://github.com/xitu/gold-miner#设计)、[人工智能](https://github.com/xitu/gold-miner#人工智能)等领域，想要查看更多优质译文请持续关注 [掘金翻译计划](https://github.com/xitu/gold-miner)、[官方微博](http://weibo.com/juejinfanyi)、[知乎专栏](https://zhuanlan.zhihu.com/juejinfanyi)。
